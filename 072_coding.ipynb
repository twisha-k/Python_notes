{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twisha-k/Python_notes/blob/main/72_coding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q61PZrHf6Upi"
      },
      "source": [
        "# Lesson 72: Logistic Regression - Univariate Classification I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze9uSJt-I-0E"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the previous classes, you have already worked on the **heart disease dataset** where you calculated the probability of a person having heart disease by examining the `chol` (cholesterol) values. The results roughly suggested that people with less cholesterol level have greater chances of heart disease and people with high cholesterol level have lesser chances of heart disease.\n",
        "\n",
        "\n",
        "Here's the box plot that we created in the previous classes to visualise the distribution of the `chol` values.\n",
        "\n",
        "<img src = 'https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/heart-disease-boxplot.png' width = 1000>\n",
        "\n",
        "From the box plot, you can observe that the first, second and third quartiles of the cholesterol values for the patients **having** heart disease (shown with the orange colour) are lower as compared to the ones for the patients **not having** it (shown with the blue colour).\n",
        "\n",
        "Hence, we concluded that people having lower cholesterol levels are more likely to have heart disease.\n",
        "\n",
        "In today's class, you will learn to classify or predict whether a person is suffering from heart disease or not based on just cholesterol values by deploying two most commonly used classification-based machine learning algorithms:\n",
        "\n",
        "1. Random Forest Classifier\n",
        "2. Logistic Regression\n",
        "\n",
        "Before we start, let's first recall the attributes or columns of the dataset.\n",
        "\n",
        "**Data Description**\n",
        "\n",
        "The Heart Disease UCI dataset contains data collected on 14 different attributes by examining 303 patients. The dataset focuses only on differentiating patients having heart disease; labelled as value 1 and those not having heart disease; labelled as value 0. The 14 attributes (or columns) are as follows:\n",
        "\n",
        "|Columns|Description|\n",
        "|-|-|\n",
        "|age|age in years|\n",
        "|sex|sex (1 = male; 0 = female)|\n",
        "|cp|chest pain type (4 values)|\n",
        "|trestbps|resting blood pressure (in mm Hg on admission to the hospital)|\n",
        "|chol|serum cholesterol in $\\frac{mg}{dl}$|\n",
        "|fbs|fasting blood sugar > 120 $\\frac{mg}{dl}$|\n",
        "|restecg|resting electrocardiographic results (values 0, 1, 2)|\n",
        "|thalach|maximum heart rate achieved|\n",
        "|exang|exercise induced angina (1 = yes; 0 = no)|\n",
        "|oldpeak|ST depression induced by exercise relative to rest|\n",
        "|slope|the slope of the peak exercise ST segment|\n",
        "|ca|number of major vessels (0-3) colored by fluoroscopy|\n",
        "|thal|A blood disorder called thalassemia|\n",
        "|target|1 = presence of heart disease; 0 = absence of heart disease|\n",
        "\n",
        "**Source:** https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpKI2pWEtREK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2UBkl1AZuRc"
      },
      "source": [
        "#### Activity 1: Loading Data\n",
        "\n",
        "Load the heart disease dataset. Here's the dataset link:\n",
        "\n",
        "https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/uci-heart-disease/heart.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmRB05lddS--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "885148f0-ad52-4b9f-cef5-b6e9f3e750bb"
      },
      "source": [
        "# S1.1: Import the required modules and load the heart disease dataset. Also, display the first five rows.\n",
        "import pandas as pd\n",
        "heart_disease=pd.read_csv('https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/uci-heart-disease/heart.csv')\n",
        "heart_disease.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33571aa3-e5cb-47e0-945f-5c31eaf3272c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33571aa3-e5cb-47e0-945f-5c31eaf3272c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33571aa3-e5cb-47e0-945f-5c31eaf3272c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33571aa3-e5cb-47e0-945f-5c31eaf3272c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1a-clG-jqPr"
      },
      "source": [
        "Let's first look at the complete information on the `df` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2x3F5XtkAGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344edffc-89d7-4d8c-e06d-71d15d55cb29"
      },
      "source": [
        "# S1.2: Apply the 'info()' function on the 'df' DataFrame.\n",
        "heart_disease.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgnxI54ckEb6"
      },
      "source": [
        "You can see there are 303 entries for each column and no missing values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al16HfwffBFB"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpw7DeLczN3f"
      },
      "source": [
        "#### Activity 2: Imbalanced Data^\n",
        "\n",
        "The target variable `target` has two values: `0` and `1`. This means that our dataset is composed of two classes or labels:\n",
        "\n",
        " - Class `0` - Patients NOT having heart disease\n",
        " - Class `1` - Patients having heart disease\n",
        "\n",
        "Such problems are known as **binary classification** problem where the target attribute can have only two possible values (for e.g. `0` and `1`).\n",
        "\n",
        "Before we start building the model, let us find out whether our dataset is balanced or not i.e. whether class distribution is uniform among all the classes. An imbalanced dataset means that the number of observations belonging to one class is significantly lower than that of the other class. Such datasets will result in a biased classifier which will hamper the results.\n",
        "\n",
        "As our dataset has two classes, then balanced data would mean 50% observations for each class. Let us calculate the number of observations for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEVBxNQQThSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a7a399b-7092-4161-b4b0-5e7246867911"
      },
      "source": [
        "# S2.1 Print the number of records in each label and their percentage in the 'target' column\n",
        "# Print the number of records with and without heart disease\n",
        "(heart_disease['target'].value_counts()*100)/heart_disease.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    54.455446\n",
              "0    45.544554\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eymgp4JPjDNa"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AFcyIZMSl07"
      },
      "source": [
        "#### Activity 3: Train-Test Split\n",
        "\n",
        "We will first predict whether a person is a heart patient or not by analysing only his/her cholesterol value. Thus, the model will use only one feature or independent variable `chol` to predict the target variable `target`.\n",
        "\n",
        "Before deploying our model, let's split the `df` DataFrame into train set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYoe69GREXWK"
      },
      "source": [
        "# S3.1: Split the DataFrame into the train and test sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(heart_disease, test_size = 0.3, random_state = 42)\n",
        "X_train=train_df['chol']#feature train\n",
        "X_test=test_df['chol']#feature test\n",
        "y_train=train_df['target']#target train\n",
        "y_test=test_df['target']#target test\n",
        "X_train_reshaped=X_train.values.reshape(-1,1)\n",
        "X_test_reshaped=X_test.values.reshape(-1,1)\n",
        "y_train_reshaped=y_train.values.reshape(-1,1)\n",
        "y_test_reshaped=y_test.values.reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5zYRSClwqFY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20N4v1sjMgGU"
      },
      "source": [
        "#### Activity 4: Applying Random Forest Classifier^^\n",
        "\n",
        "We had already explored the **Random Forest Classifier** algorithm in one of our previous classes. Let's use it to find out if it can detect the patients having heart disease accurately or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4cMnv2jyQGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616f6a3f-f3b5-48b2-f1d7-8d16352b6e8c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# S4.1: Build the Random Forest Classifier prediction model.\n",
        "sklearn_rfc=RandomForestClassifier()\n",
        "sklearn_rfc.fit(X_train_reshaped,y_train_reshaped)\n",
        "sklearn_rfc.score(X_train_reshaped,y_train_reshaped)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8537735849056604"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPO9njW_xwS1"
      },
      "source": [
        "You may observe that the model score is pretty close to 1 or 100%. Let's perform predictions using the above model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylnKkzbrT6Jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dff6b2-9943-45d2-81d7-a67e7947631e"
      },
      "source": [
        "# S4.2: Make predictions on the test dataset using the 'predict()' function.\n",
        "rfc_y_test_pred=sklearn_rfc.predict(X_test_reshaped)\n",
        "rfc_y_test_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_reshaped.shape,rfc_y_test_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03cUMoLyIhXq",
        "outputId": "33879226-c04f-4c64-eab0-8b9b10a18633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((91, 1), (91,))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaoPJ7hGUBco"
      },
      "source": [
        "Let's compute the confusion matrix to evaluate the accuracy of our classifier `rf_clf`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_kCRRwloRd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9afa0e-789b-46c9-e93e-a1ccffb6ae76"
      },
      "source": [
        "# S4.3: Display the results of 'confusion_matrix'\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "confusion_matrix(y_test_reshaped,rfc_y_test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[25, 16],\n",
              "       [23, 27]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96m-xTok2-tt"
      },
      "source": [
        "So we got the confusion matrix for our Random Forest model. Let's recall what does a confusion matrix returns as output.\n",
        "\n",
        "In this case,\n",
        " - positive outcome $\\Rightarrow$ class `1` (patients having heart disease)\n",
        " - negative outcome $\\Rightarrow$ class `0` (patients NOT having heart disease)\n",
        "\n",
        "The confusion matrix reflects the following values:\n",
        "\n",
        "1. **True Negatives (TN)** - class `0` values **correctly** predicted as class `0`.\n",
        "\n",
        "2. **True Positives (TP)** - class `1` values **correctly** predicted as class `1`.\n",
        "\n",
        "3. **False Positives (FP)** - class `0` values **incorrectly**  predicted as class `1`.\n",
        "\n",
        "4. **False Negatives (FN)** - class `1` values **incorrectly**  predicted as class `0`.\n",
        "\n",
        "\n",
        "||Predicted Class `0`|Predicted Class `1`|    \n",
        "|-|-|-|\n",
        "|Actual Class `0`|**TN = 24**|**FP = 17**|\n",
        "|Actual Class `1`|**FN = 20**|**TP = 30**|\n",
        "\n",
        "\n",
        "**Note:** Every time you build a prediction model, the predictions might be slightly different from the previous ones. Hence, the confusion matrix might have slightly different values every time.\n",
        "\n",
        "These values of confusion matrix are used for calculating precision, recall and f1-score with the below formulae:\n",
        "\n",
        "1. **Precision** - It is the ratio of the correctly predicted positive values (TP) to the total predicted positive values (TP + FP) i.e.\n",
        "\n",
        "$$\\text{precision} = \\frac{\\text{TP}}{\\text{TP + FP}}$$\n",
        "\n",
        "\n",
        "2. **Recall** -  It is the ratio of the correctly predicted positive values (TP)values to the total values (TP + FN) i.e.\n",
        "\n",
        "$$\\text{recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
        "\n",
        "\n",
        "3. **f1-score** - It is a harmonic mean of the precision and recall values, i.e.\n",
        "\n",
        "$$\\text{f1-score} = 2 \\left( \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} \\right)$$\n",
        "\n",
        "Let's take a look at precision, recall and f1-score of our model using `classification_report()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMH7f---UTVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01045119-a1d6-4a37-9540-df9e35a4f2d2"
      },
      "source": [
        "# S4.4: Display the precision, recall and f1-score values.\n",
        "print(classification_report(y_test_reshaped,rfc_y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.61      0.56        41\n",
            "           1       0.63      0.54      0.58        50\n",
            "\n",
            "    accuracy                           0.57        91\n",
            "   macro avg       0.57      0.57      0.57        91\n",
            "weighted avg       0.58      0.57      0.57        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ4fM1guUjtr"
      },
      "source": [
        "We can see that the **f1-scores** for both the labels `0` and `1` are not closed to 1. Thus, the prediction percentage is not satisfactory.  \n",
        "\n",
        "Let's verify accuracy with another classification based machine learning model **Logistic Regression**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxrVzP-_0kah"
      },
      "source": [
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_poi12der_F"
      },
      "source": [
        "#### Activity 5: Logistic Regression^^^\n",
        "\n",
        "Logistic Regression is a type of **classification** algorithm which classifies or categorises a given set of data into different class labels. In the context of heart disease dataset, logistic regression will  classify the patients either as `1` (having heart disease) or as `0` (not having heart disease).\n",
        "\n",
        "Logistic Regression is used to predict the probability of an outcome for an event. It calculates a threshold probability value. If the probability of an outcome is less than the threshold probability, then logistic regression classifies that outcome as `0`, otherwise as `1`. You will learn the technical details in the subsequent classes, but for the time being, let's build a Logistic Regression model on the train set by following the steps listed below:\n",
        "\n",
        "1. Import `LogisticRegression` class from the `sklearn.linear_model` module.\n",
        "2. Create an object of the `LogisticRegression` class, say `log_reg` and pass `n_jobs = -1` as input to its constructor.\n",
        "3. Call the `fit()` function of the `LogisticRegression` class on the object created and pass `X_train` and `y_train` as inputs to the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxtlCGgAeUkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf979332-d73d-4c8c-db61-d3568d5d4e2c"
      },
      "source": [
        "# T5.1: Deploy the 'LogisticRegression' model using the 'fit()' function.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg=LogisticRegression(n_jobs = -1)\n",
        "log_reg.fit(X_train_reshaped,y_train_reshaped)\n",
        "log_reg.score(X_train_reshaped,y_train_reshaped)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5283018867924528"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXuBKlKC0EE5"
      },
      "source": [
        "The accuracy score is less than the one obtained through `RandomForestClassifier` . However, let's make the predictions on the test set and compare them with the actual labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JMQlyNOfDAq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5084b3c6-3323-4b27-89ac-a3a9961ef7a0"
      },
      "source": [
        "# S5.1: Make predictions on the test dataset by using the 'predict()' function.\n",
        "log_y_test_pred=log_reg.predict(X_test_reshaped)\n",
        "log_y_test_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUWZiyrF0EE-"
      },
      "source": [
        "Let's compute the confusion matrix to calculate recall, precision and f1-scores\n",
        "to evaluate the logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r24aTqpxfnQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b89fe0-e386-439e-b7ed-6816968704d7"
      },
      "source": [
        "# S5.2: Display the confusion_matrix.\n",
        "confusion_matrix(y_test_reshaped,log_y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2, 39],\n",
              "       [ 0, 50]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO8P9HHCfnQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093cffe4-366a-4a20-ccf6-007e8ab8a70f"
      },
      "source": [
        "# S5.3: Display recall, precision and f1-score values.\n",
        "print(classification_report(y_test_reshaped,log_y_test_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.05      0.09        41\n",
            "           1       0.56      1.00      0.72        50\n",
            "\n",
            "    accuracy                           0.57        91\n",
            "   macro avg       0.78      0.52      0.41        91\n",
            "weighted avg       0.76      0.57      0.44        91\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxU0ezJVsqvy"
      },
      "source": [
        "The f1-score is high for class `1` which are true positives are correctly obtained through Logistic Regression. But true negatives are very low. The Random Forest Classifier model is able to get more true negatives. So both of them are unable to provide high number of true positive and high number of true negatives.\n",
        "\n",
        "You will soon get to learn how both these models work behind the scenes and then you will develop a sense of which classification model to use for different kinds of problem statements.\n",
        "\n",
        "Let us predict the labels with both classifiers on some arbitrary cholesterol values, say 180 and 260."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B97SLEbh8yP5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95597f6d-43f7-4d1f-e806-af42dfca5f8e"
      },
      "source": [
        "# S5.4: Predict labels with cholesterol levels 180 and 260 for both models\n",
        "import numpy as np\n",
        "print(sklearn_rfc.predict(np.array(180).reshape(-1,1)))\n",
        "print(sklearn_rfc.predict(np.array(260).reshape(-1,1)))\n",
        "print(log_reg.predict(np.array(180).reshape(-1,1)))\n",
        "print(log_reg.predict(np.array(260).reshape(-1,1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n",
            "[0]\n",
            "[1]\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlR83AHU0ne_"
      },
      "source": [
        "Let's stop here, in the next class, we will understand the working of Logistic Regression algorithm using sigmoid function and will also try to improve the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GObBg7R3zT9g"
      },
      "source": [
        "-----"
      ]
    }
  ]
}
