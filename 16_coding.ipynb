{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twisha-k/Python_notes/blob/main/16_coding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKsEYRKMIXz6"
      },
      "source": [
        "# Lesson 16: Hunting Exoplanets In Space - Deploying A Prediction Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdmZPtYSn7kA"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the last class, we learnt how to create line plots and scatter plots to visualise data.\n",
        "\n",
        "In this class, we will deploy a prediction model to predict which stars in the test dataset have a planet and which do not. The prediction model, through the training dataset, will learn the properties of a star that has a planet and also the properties of a star which does not have a planet. Once the model has learnt the required properties, it will look for these properties in the test dataset and according to the properties it sees, it will predict whether a star has a planet or not.\n",
        "\n",
        "In this class, we will learn how to deploy the **Random Forest Classifier** model (a machine learning algorithm). Machine learning is a branch of artificial intelligence in which a machine learns through data the different features on its own without being programmed by a computer programmer.\n",
        "\n",
        "\n",
        "<img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-14/ml-vs-ai.png' width=700>\n",
        "\n",
        "In this case, the machine will learn to recognise the flux values of stars having a planet on its own. When a new dataset containing only the flux values of a star is shown to the machine, it will tell the star having a planet and not having a planet.\n",
        "\n",
        "There are many machine learning models or algorithms to do this kind of prediction. One of them is **Random Forest Classifier**. It is used to classify outcomes into classes (or labels) based on some features. For e.g., an animal that makes a 'Meow! Meow!' sound is classified (or labelled) as a cat, an animal that makes a 'Woof! Woof!' sound is classified as a dog, an animal which makes a hissing sound is classified as a snake etc.\n",
        "\n",
        "In this lesson, we will use the Random Forest Classifier model to classify whether a star has a planet or not. The stars which have at least one planet are labelled as `2` while the stars not having a planet are labelled as `1`.\n",
        "\n",
        "\n",
        "Let's run all the codes in the code cells that we have already covered in the previous classes and begin this class from **Activity 1: The `value_counts()` Function** section.  You too run the code cells until the first activity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq9mAtEg9cpZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwzryU6Zie33"
      },
      "source": [
        "#### Loading The Datasets\n",
        "\n",
        "Create a Pandas DataFrame every time you start a Jupyter notebook.\n",
        "\n",
        "Dataset links (Don't click on them):\n",
        "\n",
        "1. Train dataset\n",
        "\n",
        "   https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTrain.csv\n",
        "\n",
        "2. Test dataset\n",
        "   \n",
        "   https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTest.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjScdqmQstFg"
      },
      "source": [
        "# Loading both the training and test datasets.\n",
        "import pandas as pd\n",
        "\n",
        "exo_train_df = pd.read_csv('https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTrain.csv')\n",
        "exo_test_df = pd.read_csv('https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/kepler-exoplanets-dataset/exoTest.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "_v1Kq4jMkQao",
        "outputId": "d9341dae-16fb-4a34-cbb0-080a14792d01"
      },
      "source": [
        "exo_train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>FLUX.1</th>\n",
              "      <th>FLUX.2</th>\n",
              "      <th>FLUX.3</th>\n",
              "      <th>FLUX.4</th>\n",
              "      <th>FLUX.5</th>\n",
              "      <th>FLUX.6</th>\n",
              "      <th>FLUX.7</th>\n",
              "      <th>FLUX.8</th>\n",
              "      <th>FLUX.9</th>\n",
              "      <th>FLUX.10</th>\n",
              "      <th>FLUX.11</th>\n",
              "      <th>FLUX.12</th>\n",
              "      <th>FLUX.13</th>\n",
              "      <th>FLUX.14</th>\n",
              "      <th>FLUX.15</th>\n",
              "      <th>FLUX.16</th>\n",
              "      <th>FLUX.17</th>\n",
              "      <th>FLUX.18</th>\n",
              "      <th>FLUX.19</th>\n",
              "      <th>FLUX.20</th>\n",
              "      <th>FLUX.21</th>\n",
              "      <th>FLUX.22</th>\n",
              "      <th>FLUX.23</th>\n",
              "      <th>FLUX.24</th>\n",
              "      <th>FLUX.25</th>\n",
              "      <th>FLUX.26</th>\n",
              "      <th>FLUX.27</th>\n",
              "      <th>FLUX.28</th>\n",
              "      <th>FLUX.29</th>\n",
              "      <th>FLUX.30</th>\n",
              "      <th>FLUX.31</th>\n",
              "      <th>FLUX.32</th>\n",
              "      <th>FLUX.33</th>\n",
              "      <th>FLUX.34</th>\n",
              "      <th>FLUX.35</th>\n",
              "      <th>FLUX.36</th>\n",
              "      <th>FLUX.37</th>\n",
              "      <th>FLUX.38</th>\n",
              "      <th>FLUX.39</th>\n",
              "      <th>...</th>\n",
              "      <th>FLUX.3158</th>\n",
              "      <th>FLUX.3159</th>\n",
              "      <th>FLUX.3160</th>\n",
              "      <th>FLUX.3161</th>\n",
              "      <th>FLUX.3162</th>\n",
              "      <th>FLUX.3163</th>\n",
              "      <th>FLUX.3164</th>\n",
              "      <th>FLUX.3165</th>\n",
              "      <th>FLUX.3166</th>\n",
              "      <th>FLUX.3167</th>\n",
              "      <th>FLUX.3168</th>\n",
              "      <th>FLUX.3169</th>\n",
              "      <th>FLUX.3170</th>\n",
              "      <th>FLUX.3171</th>\n",
              "      <th>FLUX.3172</th>\n",
              "      <th>FLUX.3173</th>\n",
              "      <th>FLUX.3174</th>\n",
              "      <th>FLUX.3175</th>\n",
              "      <th>FLUX.3176</th>\n",
              "      <th>FLUX.3177</th>\n",
              "      <th>FLUX.3178</th>\n",
              "      <th>FLUX.3179</th>\n",
              "      <th>FLUX.3180</th>\n",
              "      <th>FLUX.3181</th>\n",
              "      <th>FLUX.3182</th>\n",
              "      <th>FLUX.3183</th>\n",
              "      <th>FLUX.3184</th>\n",
              "      <th>FLUX.3185</th>\n",
              "      <th>FLUX.3186</th>\n",
              "      <th>FLUX.3187</th>\n",
              "      <th>FLUX.3188</th>\n",
              "      <th>FLUX.3189</th>\n",
              "      <th>FLUX.3190</th>\n",
              "      <th>FLUX.3191</th>\n",
              "      <th>FLUX.3192</th>\n",
              "      <th>FLUX.3193</th>\n",
              "      <th>FLUX.3194</th>\n",
              "      <th>FLUX.3195</th>\n",
              "      <th>FLUX.3196</th>\n",
              "      <th>FLUX.3197</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>93.85</td>\n",
              "      <td>83.81</td>\n",
              "      <td>20.10</td>\n",
              "      <td>-26.98</td>\n",
              "      <td>-39.56</td>\n",
              "      <td>-124.71</td>\n",
              "      <td>-135.18</td>\n",
              "      <td>-96.27</td>\n",
              "      <td>-79.89</td>\n",
              "      <td>-160.17</td>\n",
              "      <td>-207.47</td>\n",
              "      <td>-154.88</td>\n",
              "      <td>-173.71</td>\n",
              "      <td>-146.56</td>\n",
              "      <td>-120.26</td>\n",
              "      <td>-102.85</td>\n",
              "      <td>-98.71</td>\n",
              "      <td>-48.42</td>\n",
              "      <td>-86.57</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>-25.85</td>\n",
              "      <td>-67.39</td>\n",
              "      <td>-36.55</td>\n",
              "      <td>-87.01</td>\n",
              "      <td>-97.72</td>\n",
              "      <td>-131.59</td>\n",
              "      <td>-134.80</td>\n",
              "      <td>-186.97</td>\n",
              "      <td>-244.32</td>\n",
              "      <td>-225.76</td>\n",
              "      <td>-229.60</td>\n",
              "      <td>-253.48</td>\n",
              "      <td>-145.74</td>\n",
              "      <td>-145.74</td>\n",
              "      <td>30.47</td>\n",
              "      <td>-173.39</td>\n",
              "      <td>-187.56</td>\n",
              "      <td>-192.88</td>\n",
              "      <td>-182.76</td>\n",
              "      <td>...</td>\n",
              "      <td>-167.69</td>\n",
              "      <td>-56.86</td>\n",
              "      <td>7.56</td>\n",
              "      <td>37.40</td>\n",
              "      <td>-81.13</td>\n",
              "      <td>-20.10</td>\n",
              "      <td>-30.34</td>\n",
              "      <td>-320.48</td>\n",
              "      <td>-320.48</td>\n",
              "      <td>-287.72</td>\n",
              "      <td>-351.25</td>\n",
              "      <td>-70.07</td>\n",
              "      <td>-194.34</td>\n",
              "      <td>-106.47</td>\n",
              "      <td>-14.80</td>\n",
              "      <td>63.13</td>\n",
              "      <td>130.03</td>\n",
              "      <td>76.43</td>\n",
              "      <td>131.90</td>\n",
              "      <td>-193.16</td>\n",
              "      <td>-193.16</td>\n",
              "      <td>-89.26</td>\n",
              "      <td>-17.56</td>\n",
              "      <td>-17.31</td>\n",
              "      <td>125.62</td>\n",
              "      <td>68.87</td>\n",
              "      <td>100.01</td>\n",
              "      <td>-9.60</td>\n",
              "      <td>-25.39</td>\n",
              "      <td>-16.51</td>\n",
              "      <td>-78.07</td>\n",
              "      <td>-102.15</td>\n",
              "      <td>-102.15</td>\n",
              "      <td>25.13</td>\n",
              "      <td>48.57</td>\n",
              "      <td>92.54</td>\n",
              "      <td>39.32</td>\n",
              "      <td>61.42</td>\n",
              "      <td>5.08</td>\n",
              "      <td>-39.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-38.88</td>\n",
              "      <td>-33.83</td>\n",
              "      <td>-58.54</td>\n",
              "      <td>-40.09</td>\n",
              "      <td>-79.31</td>\n",
              "      <td>-72.81</td>\n",
              "      <td>-86.55</td>\n",
              "      <td>-85.33</td>\n",
              "      <td>-83.97</td>\n",
              "      <td>-73.38</td>\n",
              "      <td>-86.51</td>\n",
              "      <td>-74.97</td>\n",
              "      <td>-73.15</td>\n",
              "      <td>-86.13</td>\n",
              "      <td>-76.57</td>\n",
              "      <td>-61.27</td>\n",
              "      <td>-37.23</td>\n",
              "      <td>-48.53</td>\n",
              "      <td>-30.96</td>\n",
              "      <td>-8.14</td>\n",
              "      <td>-5.54</td>\n",
              "      <td>15.79</td>\n",
              "      <td>45.71</td>\n",
              "      <td>10.61</td>\n",
              "      <td>40.66</td>\n",
              "      <td>16.70</td>\n",
              "      <td>15.18</td>\n",
              "      <td>11.98</td>\n",
              "      <td>-203.70</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>17.02</td>\n",
              "      <td>-8.50</td>\n",
              "      <td>-13.87</td>\n",
              "      <td>-29.10</td>\n",
              "      <td>-34.29</td>\n",
              "      <td>...</td>\n",
              "      <td>-36.75</td>\n",
              "      <td>-15.49</td>\n",
              "      <td>-13.24</td>\n",
              "      <td>20.46</td>\n",
              "      <td>-1.47</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>27.80</td>\n",
              "      <td>-58.20</td>\n",
              "      <td>-58.20</td>\n",
              "      <td>-72.04</td>\n",
              "      <td>-58.01</td>\n",
              "      <td>-30.92</td>\n",
              "      <td>-13.42</td>\n",
              "      <td>-13.98</td>\n",
              "      <td>-5.43</td>\n",
              "      <td>8.71</td>\n",
              "      <td>1.80</td>\n",
              "      <td>36.59</td>\n",
              "      <td>-9.80</td>\n",
              "      <td>-19.53</td>\n",
              "      <td>-19.53</td>\n",
              "      <td>-24.32</td>\n",
              "      <td>-23.88</td>\n",
              "      <td>-33.07</td>\n",
              "      <td>-9.03</td>\n",
              "      <td>3.75</td>\n",
              "      <td>11.61</td>\n",
              "      <td>-12.66</td>\n",
              "      <td>-5.69</td>\n",
              "      <td>12.53</td>\n",
              "      <td>-3.28</td>\n",
              "      <td>-32.21</td>\n",
              "      <td>-32.21</td>\n",
              "      <td>-24.89</td>\n",
              "      <td>-4.86</td>\n",
              "      <td>0.76</td>\n",
              "      <td>-11.70</td>\n",
              "      <td>6.46</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>532.64</td>\n",
              "      <td>535.92</td>\n",
              "      <td>513.73</td>\n",
              "      <td>496.92</td>\n",
              "      <td>456.45</td>\n",
              "      <td>466.00</td>\n",
              "      <td>464.50</td>\n",
              "      <td>486.39</td>\n",
              "      <td>436.56</td>\n",
              "      <td>484.39</td>\n",
              "      <td>469.66</td>\n",
              "      <td>462.30</td>\n",
              "      <td>492.23</td>\n",
              "      <td>441.20</td>\n",
              "      <td>483.17</td>\n",
              "      <td>481.28</td>\n",
              "      <td>535.31</td>\n",
              "      <td>554.34</td>\n",
              "      <td>562.80</td>\n",
              "      <td>540.14</td>\n",
              "      <td>576.34</td>\n",
              "      <td>551.67</td>\n",
              "      <td>556.69</td>\n",
              "      <td>550.86</td>\n",
              "      <td>577.33</td>\n",
              "      <td>562.08</td>\n",
              "      <td>577.97</td>\n",
              "      <td>530.67</td>\n",
              "      <td>553.27</td>\n",
              "      <td>538.33</td>\n",
              "      <td>527.17</td>\n",
              "      <td>532.50</td>\n",
              "      <td>273.66</td>\n",
              "      <td>273.66</td>\n",
              "      <td>292.39</td>\n",
              "      <td>298.44</td>\n",
              "      <td>252.64</td>\n",
              "      <td>233.58</td>\n",
              "      <td>171.41</td>\n",
              "      <td>...</td>\n",
              "      <td>-51.09</td>\n",
              "      <td>-33.30</td>\n",
              "      <td>-61.53</td>\n",
              "      <td>-89.61</td>\n",
              "      <td>-69.17</td>\n",
              "      <td>-86.47</td>\n",
              "      <td>-140.91</td>\n",
              "      <td>-84.20</td>\n",
              "      <td>-84.20</td>\n",
              "      <td>-89.09</td>\n",
              "      <td>-55.44</td>\n",
              "      <td>-61.05</td>\n",
              "      <td>-29.17</td>\n",
              "      <td>-63.80</td>\n",
              "      <td>-57.61</td>\n",
              "      <td>2.70</td>\n",
              "      <td>-31.25</td>\n",
              "      <td>-47.09</td>\n",
              "      <td>-6.53</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.00</td>\n",
              "      <td>-25.05</td>\n",
              "      <td>-34.98</td>\n",
              "      <td>-32.08</td>\n",
              "      <td>-17.06</td>\n",
              "      <td>-27.77</td>\n",
              "      <td>7.86</td>\n",
              "      <td>-70.77</td>\n",
              "      <td>-64.44</td>\n",
              "      <td>-83.83</td>\n",
              "      <td>-71.69</td>\n",
              "      <td>13.31</td>\n",
              "      <td>13.31</td>\n",
              "      <td>-29.89</td>\n",
              "      <td>-20.88</td>\n",
              "      <td>5.06</td>\n",
              "      <td>-11.80</td>\n",
              "      <td>-28.91</td>\n",
              "      <td>-70.02</td>\n",
              "      <td>-96.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>326.52</td>\n",
              "      <td>347.39</td>\n",
              "      <td>302.35</td>\n",
              "      <td>298.13</td>\n",
              "      <td>317.74</td>\n",
              "      <td>312.70</td>\n",
              "      <td>322.33</td>\n",
              "      <td>311.31</td>\n",
              "      <td>312.42</td>\n",
              "      <td>323.33</td>\n",
              "      <td>311.14</td>\n",
              "      <td>326.19</td>\n",
              "      <td>313.11</td>\n",
              "      <td>313.89</td>\n",
              "      <td>317.96</td>\n",
              "      <td>330.92</td>\n",
              "      <td>341.10</td>\n",
              "      <td>360.58</td>\n",
              "      <td>370.29</td>\n",
              "      <td>369.71</td>\n",
              "      <td>339.00</td>\n",
              "      <td>336.24</td>\n",
              "      <td>319.31</td>\n",
              "      <td>321.56</td>\n",
              "      <td>308.02</td>\n",
              "      <td>296.82</td>\n",
              "      <td>279.34</td>\n",
              "      <td>275.78</td>\n",
              "      <td>289.67</td>\n",
              "      <td>281.33</td>\n",
              "      <td>285.37</td>\n",
              "      <td>281.87</td>\n",
              "      <td>88.75</td>\n",
              "      <td>88.75</td>\n",
              "      <td>67.71</td>\n",
              "      <td>74.46</td>\n",
              "      <td>69.34</td>\n",
              "      <td>76.51</td>\n",
              "      <td>80.26</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.75</td>\n",
              "      <td>14.29</td>\n",
              "      <td>-14.18</td>\n",
              "      <td>-25.14</td>\n",
              "      <td>-13.43</td>\n",
              "      <td>-14.74</td>\n",
              "      <td>2.24</td>\n",
              "      <td>-31.07</td>\n",
              "      <td>-31.07</td>\n",
              "      <td>-50.27</td>\n",
              "      <td>-39.22</td>\n",
              "      <td>-51.33</td>\n",
              "      <td>-18.53</td>\n",
              "      <td>-1.99</td>\n",
              "      <td>10.43</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>-15.32</td>\n",
              "      <td>-23.38</td>\n",
              "      <td>-27.71</td>\n",
              "      <td>-36.12</td>\n",
              "      <td>-36.12</td>\n",
              "      <td>-15.65</td>\n",
              "      <td>6.63</td>\n",
              "      <td>10.66</td>\n",
              "      <td>-8.57</td>\n",
              "      <td>-8.29</td>\n",
              "      <td>-21.90</td>\n",
              "      <td>-25.80</td>\n",
              "      <td>-29.86</td>\n",
              "      <td>7.42</td>\n",
              "      <td>5.71</td>\n",
              "      <td>-3.73</td>\n",
              "      <td>-3.73</td>\n",
              "      <td>30.05</td>\n",
              "      <td>20.03</td>\n",
              "      <td>-12.67</td>\n",
              "      <td>-8.77</td>\n",
              "      <td>-17.31</td>\n",
              "      <td>-17.35</td>\n",
              "      <td>13.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1107.21</td>\n",
              "      <td>-1112.59</td>\n",
              "      <td>-1118.95</td>\n",
              "      <td>-1095.10</td>\n",
              "      <td>-1057.55</td>\n",
              "      <td>-1034.48</td>\n",
              "      <td>-998.34</td>\n",
              "      <td>-1022.71</td>\n",
              "      <td>-989.57</td>\n",
              "      <td>-970.88</td>\n",
              "      <td>-933.30</td>\n",
              "      <td>-889.49</td>\n",
              "      <td>-888.66</td>\n",
              "      <td>-853.95</td>\n",
              "      <td>-800.91</td>\n",
              "      <td>-754.48</td>\n",
              "      <td>-717.24</td>\n",
              "      <td>-649.34</td>\n",
              "      <td>-605.71</td>\n",
              "      <td>-575.62</td>\n",
              "      <td>-526.37</td>\n",
              "      <td>-490.12</td>\n",
              "      <td>-458.73</td>\n",
              "      <td>-447.76</td>\n",
              "      <td>-419.54</td>\n",
              "      <td>-410.76</td>\n",
              "      <td>-404.10</td>\n",
              "      <td>-425.38</td>\n",
              "      <td>-397.29</td>\n",
              "      <td>-412.73</td>\n",
              "      <td>-446.49</td>\n",
              "      <td>-413.46</td>\n",
              "      <td>-1006.21</td>\n",
              "      <td>-1006.21</td>\n",
              "      <td>-973.29</td>\n",
              "      <td>-986.01</td>\n",
              "      <td>-975.88</td>\n",
              "      <td>-982.20</td>\n",
              "      <td>-953.73</td>\n",
              "      <td>...</td>\n",
              "      <td>-694.76</td>\n",
              "      <td>-705.01</td>\n",
              "      <td>-625.24</td>\n",
              "      <td>-604.16</td>\n",
              "      <td>-668.26</td>\n",
              "      <td>-742.18</td>\n",
              "      <td>-820.55</td>\n",
              "      <td>-874.76</td>\n",
              "      <td>-874.76</td>\n",
              "      <td>-853.68</td>\n",
              "      <td>-808.62</td>\n",
              "      <td>-777.88</td>\n",
              "      <td>-712.62</td>\n",
              "      <td>-694.01</td>\n",
              "      <td>-655.74</td>\n",
              "      <td>-599.74</td>\n",
              "      <td>-617.30</td>\n",
              "      <td>-602.98</td>\n",
              "      <td>-539.29</td>\n",
              "      <td>-672.71</td>\n",
              "      <td>-672.71</td>\n",
              "      <td>-594.49</td>\n",
              "      <td>-597.60</td>\n",
              "      <td>-560.77</td>\n",
              "      <td>-501.95</td>\n",
              "      <td>-461.62</td>\n",
              "      <td>-468.59</td>\n",
              "      <td>-513.24</td>\n",
              "      <td>-504.70</td>\n",
              "      <td>-521.95</td>\n",
              "      <td>-594.37</td>\n",
              "      <td>-401.66</td>\n",
              "      <td>-401.66</td>\n",
              "      <td>-357.24</td>\n",
              "      <td>-443.76</td>\n",
              "      <td>-438.54</td>\n",
              "      <td>-399.71</td>\n",
              "      <td>-384.65</td>\n",
              "      <td>-411.79</td>\n",
              "      <td>-510.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3198 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   LABEL   FLUX.1   FLUX.2   FLUX.3  ...  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197\n",
              "0      2    93.85    83.81    20.10  ...      39.32      61.42       5.08     -39.54\n",
              "1      2   -38.88   -33.83   -58.54  ...     -11.70       6.46      16.00      19.93\n",
              "2      2   532.64   535.92   513.73  ...     -11.80     -28.91     -70.02     -96.67\n",
              "3      2   326.52   347.39   302.35  ...      -8.77     -17.31     -17.35      13.98\n",
              "4      2 -1107.21 -1112.59 -1118.95  ...    -399.71    -384.65    -411.79    -510.54\n",
              "\n",
              "[5 rows x 3198 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcXAl_LogQo_",
        "outputId": "4bc97434-741d-41e3-ce91-fc0ca7a352ff"
      },
      "source": [
        "exo_train_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['LABEL', 'FLUX.1', 'FLUX.2', 'FLUX.3', 'FLUX.4', 'FLUX.5', 'FLUX.6',\n",
              "       'FLUX.7', 'FLUX.8', 'FLUX.9',\n",
              "       ...\n",
              "       'FLUX.3188', 'FLUX.3189', 'FLUX.3190', 'FLUX.3191', 'FLUX.3192',\n",
              "       'FLUX.3193', 'FLUX.3194', 'FLUX.3195', 'FLUX.3196', 'FLUX.3197'],\n",
              "      dtype='object', length=3198)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGcwb3Ax10u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118f7d8b-fcc1-473d-8eb2-7d11a6f6d26a"
      },
      "source": [
        "# Number of rows and columns in the DataFrames.\n",
        "print(exo_train_df.shape)\n",
        "exo_test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5087, 3198)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(570, 3198)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VG6uuL7eq3f"
      },
      "source": [
        "In the previous classes, we have already checked that the training dataset does not have any missing value. So, we can skip the missing values check part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob_UHtcNaE-s"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcKiuR0gIvqi"
      },
      "source": [
        "#### Activity 1: The `value_counts()` Function\n",
        "Our prediction model should classify the stars either as `1` or `2`. Let's find out how many stars in the test dataset are classified as `1` and `2`.\n",
        "\n",
        "To compute how many times a value occurs in a series, we use the `value_counts()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG6oVSvRK6Jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b19091-d800-4512-8075-24535bc1e586"
      },
      "source": [
        "# Student Action: Count the number of times a value occurs in a Pandas series.\n",
        "print(exo_train_df['LABEL'].value_counts())\n",
        "print(exo_test_df['LABEL'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    5050\n",
            "2      37\n",
            "Name: LABEL, dtype: int64\n",
            "1    565\n",
            "2      5\n",
            "Name: LABEL, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l7BTsS7LNLE"
      },
      "source": [
        "There are `565` stars which are classified as `1` and `5` stars classified as `2` which means only `5` stars have a planet. Interestingly, if our prediction model mindlessly classifies every star as `1`, then it is a very accurate model. Why?\n",
        "\n",
        "Because the accuracy of a model is calculated as **a percentage of the correct predictions out of the total number of predictions**. In this case, the percentage of the correct predictions is\n",
        "\n",
        " $\\frac{565\\times100}{570} = 99.122$ %\n",
        "\n",
        "Thus, without actually deploying a proper prediction model, we can predict the stars having a planet with 99% accuracy.\n",
        "\n",
        "This is **WRONG**! This is where we need to be careful. Because we have very imbalanced data. The ultimate goal of the Kepler space telescope is to detect exoplanets in outer space. Hence, a machine learning model, based on some data should also **correctly** detect stars having planets. This means a prediction model will be considered useful if it correctly detects almost all the stars having a planet.\n",
        "\n",
        "So, the prediction model which always labels every star as `1` is useless. Because it must detect almost all the stars having a planet.\n",
        "\n",
        "Now, we are going to deploy the Random Forest Classifier model so that it can detect all the five (or at least three) stars having a planet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmlkMPBed0wi"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbbP1ucnjism"
      },
      "source": [
        "### Random Forest Classifier^\n",
        "\n",
        "A Random Forest is a collection (a.k.a. ensemble) of many decision trees. A decision tree is a flow chart which separates data based on some condition. If a condition is true, you move on a path otherwise, you move on to another path.\n",
        "\n",
        "\n",
        "For e.g., in case of finding a star having a planet, you can construct the following decision tree:\n",
        "\n",
        "<img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-14/decision-tree.png' width=600>\n",
        "\n",
        "You could ask a question whether there is decrease in the flux values of a star. If the answer is no, then it clearly means the star does not have a planet. However, if the answer is yes, then you could ask another question to check whether the decrease is periodic or not. Again, if the answer is no, then the star does not have a planet. Otherwise, it has a planet.\n",
        "\n",
        "This is one of the examples of a decision tree. Based on a problem, the decision tree could get more and more complex.\n",
        "\n",
        "A collection of `N` number of trees is a random forest wherein each tree gives some predicted value (in this case either class `1` or class `2`).\n",
        "\n",
        "<img src='https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/images/lesson-14/rfc-image.jpg' width=800>\n",
        "\n",
        "The final predicted value is the majority class, i.e, the class that is predicted by the most number of decision trees in a random forest.\n",
        "\n",
        "For the time being, just consider the Random Forest Classifier as some kind of a black-box which classifies data into different classes (in this case, either class `1` or class `2`) by learning the properties of every class through a training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zr_egypdy1R"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3PeA6-AaO5J"
      },
      "source": [
        "#### Activity 2: Importing `RandomForestClassifier`\n",
        "\n",
        "We need to import a module called `RandomForestClassifier` from a package called `sklearn.ensemble`. The `sklearn` (or **scikit-learn**) is a collection of many machine learning modules. Almost every machine learning algorithm can be directly applied without a knowledge of math using the **scikit-learn** library. It is kind of a plug-and-play device.\n",
        "\n",
        "You can read about it in the link provided in the **Activities** section under the title **`scikit-learn` - Random Forest Classifier**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjyPky3Hh0fu"
      },
      "source": [
        "# Teacher Action: Import the required modules from the 'sklearn' library.\n",
        "# Import the 'RandomForestClassifier' module from the 'sklearn.ensemble' library.\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuNU9pO2j7V0",
        "outputId": "2f488677-2fff-4d6f-e72e-8ec05f7c58cf"
      },
      "source": [
        "#to get a column\n",
        "exo_train_df[\"LABEL\"]\n",
        "#for the iloc\n",
        "#syntax for iloc exo_train_df.iloc[row_start:row_end,column_start:column_end]\n",
        "x_train_target = exo_train_df.iloc[:,0]\n",
        "x_train_target\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2\n",
              "1       2\n",
              "2       2\n",
              "3       2\n",
              "4       2\n",
              "       ..\n",
              "5082    1\n",
              "5083    1\n",
              "5084    1\n",
              "5085    1\n",
              "5086    1\n",
              "Name: LABEL, Length: 5087, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8FljiKddvz9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP_x1sHBbWce"
      },
      "source": [
        "#### Activity 3: Target & Feature Variables Separation\n",
        "\n",
        "The `RandomForestClassifier` module has a function called `fit()` which takes two inputs. The first input is the collection of feature variables.\n",
        "\n",
        "*The features are those variables which describe the features or properties of an entity.* In this case, the `FLUX.1` to `FLUX.3197` are feature variables. Hence, the values stored in these columns are the features of a star in exoplanets dataset.\n",
        "\n",
        "The second input is the target variable.\n",
        "\n",
        "*The variable which needs to be predicted is called a target variable.* In this case, the `LABEL` is the target variable because the prediction model needs to predict which star belongs to which class in the test dataset. Hence, the values stored in the `LABEL` column are the target values.\n",
        "\n",
        "So, we need to extract the target variable and the feature variables separately from the training dataset.\n",
        "\n",
        "Let's store the feature variables in the `x_train` variable and the target variable in the `y_train` variable. We will separate the features using the `iloc[]` function.\n",
        "\n",
        "We need all the rows from the training set. So, inside the `iloc[]` function, we will enter the colon (`:`) sign to get all the rows. We do not need the first column, i.e., the `LABEL` column. Therefore, inside the `iloc[]` function, as part of column indexing, enter `1` as the starting index followed by the colon (`:`) sign to include the rest of the columns from the training dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4xbNQzYj_CM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "026c4bd7-a767-42a5-e05d-3f9a4ec94b30"
      },
      "source": [
        "# Student Action: Extract the feature variables from the training dataset using the 'iloc[]' function.\n",
        "x_train = exo_train_df.iloc[:,1:]\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLUX.1</th>\n",
              "      <th>FLUX.2</th>\n",
              "      <th>FLUX.3</th>\n",
              "      <th>FLUX.4</th>\n",
              "      <th>FLUX.5</th>\n",
              "      <th>FLUX.6</th>\n",
              "      <th>FLUX.7</th>\n",
              "      <th>FLUX.8</th>\n",
              "      <th>FLUX.9</th>\n",
              "      <th>FLUX.10</th>\n",
              "      <th>FLUX.11</th>\n",
              "      <th>FLUX.12</th>\n",
              "      <th>FLUX.13</th>\n",
              "      <th>FLUX.14</th>\n",
              "      <th>FLUX.15</th>\n",
              "      <th>FLUX.16</th>\n",
              "      <th>FLUX.17</th>\n",
              "      <th>FLUX.18</th>\n",
              "      <th>FLUX.19</th>\n",
              "      <th>FLUX.20</th>\n",
              "      <th>FLUX.21</th>\n",
              "      <th>FLUX.22</th>\n",
              "      <th>FLUX.23</th>\n",
              "      <th>FLUX.24</th>\n",
              "      <th>FLUX.25</th>\n",
              "      <th>FLUX.26</th>\n",
              "      <th>FLUX.27</th>\n",
              "      <th>FLUX.28</th>\n",
              "      <th>FLUX.29</th>\n",
              "      <th>FLUX.30</th>\n",
              "      <th>FLUX.31</th>\n",
              "      <th>FLUX.32</th>\n",
              "      <th>FLUX.33</th>\n",
              "      <th>FLUX.34</th>\n",
              "      <th>FLUX.35</th>\n",
              "      <th>FLUX.36</th>\n",
              "      <th>FLUX.37</th>\n",
              "      <th>FLUX.38</th>\n",
              "      <th>FLUX.39</th>\n",
              "      <th>FLUX.40</th>\n",
              "      <th>...</th>\n",
              "      <th>FLUX.3158</th>\n",
              "      <th>FLUX.3159</th>\n",
              "      <th>FLUX.3160</th>\n",
              "      <th>FLUX.3161</th>\n",
              "      <th>FLUX.3162</th>\n",
              "      <th>FLUX.3163</th>\n",
              "      <th>FLUX.3164</th>\n",
              "      <th>FLUX.3165</th>\n",
              "      <th>FLUX.3166</th>\n",
              "      <th>FLUX.3167</th>\n",
              "      <th>FLUX.3168</th>\n",
              "      <th>FLUX.3169</th>\n",
              "      <th>FLUX.3170</th>\n",
              "      <th>FLUX.3171</th>\n",
              "      <th>FLUX.3172</th>\n",
              "      <th>FLUX.3173</th>\n",
              "      <th>FLUX.3174</th>\n",
              "      <th>FLUX.3175</th>\n",
              "      <th>FLUX.3176</th>\n",
              "      <th>FLUX.3177</th>\n",
              "      <th>FLUX.3178</th>\n",
              "      <th>FLUX.3179</th>\n",
              "      <th>FLUX.3180</th>\n",
              "      <th>FLUX.3181</th>\n",
              "      <th>FLUX.3182</th>\n",
              "      <th>FLUX.3183</th>\n",
              "      <th>FLUX.3184</th>\n",
              "      <th>FLUX.3185</th>\n",
              "      <th>FLUX.3186</th>\n",
              "      <th>FLUX.3187</th>\n",
              "      <th>FLUX.3188</th>\n",
              "      <th>FLUX.3189</th>\n",
              "      <th>FLUX.3190</th>\n",
              "      <th>FLUX.3191</th>\n",
              "      <th>FLUX.3192</th>\n",
              "      <th>FLUX.3193</th>\n",
              "      <th>FLUX.3194</th>\n",
              "      <th>FLUX.3195</th>\n",
              "      <th>FLUX.3196</th>\n",
              "      <th>FLUX.3197</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>93.85</td>\n",
              "      <td>83.81</td>\n",
              "      <td>20.10</td>\n",
              "      <td>-26.98</td>\n",
              "      <td>-39.56</td>\n",
              "      <td>-124.71</td>\n",
              "      <td>-135.18</td>\n",
              "      <td>-96.27</td>\n",
              "      <td>-79.89</td>\n",
              "      <td>-160.17</td>\n",
              "      <td>-207.47</td>\n",
              "      <td>-154.88</td>\n",
              "      <td>-173.71</td>\n",
              "      <td>-146.56</td>\n",
              "      <td>-120.26</td>\n",
              "      <td>-102.85</td>\n",
              "      <td>-98.71</td>\n",
              "      <td>-48.42</td>\n",
              "      <td>-86.57</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>-25.85</td>\n",
              "      <td>-67.39</td>\n",
              "      <td>-36.55</td>\n",
              "      <td>-87.01</td>\n",
              "      <td>-97.72</td>\n",
              "      <td>-131.59</td>\n",
              "      <td>-134.80</td>\n",
              "      <td>-186.97</td>\n",
              "      <td>-244.32</td>\n",
              "      <td>-225.76</td>\n",
              "      <td>-229.60</td>\n",
              "      <td>-253.48</td>\n",
              "      <td>-145.74</td>\n",
              "      <td>-145.74</td>\n",
              "      <td>30.47</td>\n",
              "      <td>-173.39</td>\n",
              "      <td>-187.56</td>\n",
              "      <td>-192.88</td>\n",
              "      <td>-182.76</td>\n",
              "      <td>-195.99</td>\n",
              "      <td>...</td>\n",
              "      <td>-167.69</td>\n",
              "      <td>-56.86</td>\n",
              "      <td>7.56</td>\n",
              "      <td>37.40</td>\n",
              "      <td>-81.13</td>\n",
              "      <td>-20.10</td>\n",
              "      <td>-30.34</td>\n",
              "      <td>-320.48</td>\n",
              "      <td>-320.48</td>\n",
              "      <td>-287.72</td>\n",
              "      <td>-351.25</td>\n",
              "      <td>-70.07</td>\n",
              "      <td>-194.34</td>\n",
              "      <td>-106.47</td>\n",
              "      <td>-14.80</td>\n",
              "      <td>63.13</td>\n",
              "      <td>130.03</td>\n",
              "      <td>76.43</td>\n",
              "      <td>131.90</td>\n",
              "      <td>-193.16</td>\n",
              "      <td>-193.16</td>\n",
              "      <td>-89.26</td>\n",
              "      <td>-17.56</td>\n",
              "      <td>-17.31</td>\n",
              "      <td>125.62</td>\n",
              "      <td>68.87</td>\n",
              "      <td>100.01</td>\n",
              "      <td>-9.60</td>\n",
              "      <td>-25.39</td>\n",
              "      <td>-16.51</td>\n",
              "      <td>-78.07</td>\n",
              "      <td>-102.15</td>\n",
              "      <td>-102.15</td>\n",
              "      <td>25.13</td>\n",
              "      <td>48.57</td>\n",
              "      <td>92.54</td>\n",
              "      <td>39.32</td>\n",
              "      <td>61.42</td>\n",
              "      <td>5.08</td>\n",
              "      <td>-39.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-38.88</td>\n",
              "      <td>-33.83</td>\n",
              "      <td>-58.54</td>\n",
              "      <td>-40.09</td>\n",
              "      <td>-79.31</td>\n",
              "      <td>-72.81</td>\n",
              "      <td>-86.55</td>\n",
              "      <td>-85.33</td>\n",
              "      <td>-83.97</td>\n",
              "      <td>-73.38</td>\n",
              "      <td>-86.51</td>\n",
              "      <td>-74.97</td>\n",
              "      <td>-73.15</td>\n",
              "      <td>-86.13</td>\n",
              "      <td>-76.57</td>\n",
              "      <td>-61.27</td>\n",
              "      <td>-37.23</td>\n",
              "      <td>-48.53</td>\n",
              "      <td>-30.96</td>\n",
              "      <td>-8.14</td>\n",
              "      <td>-5.54</td>\n",
              "      <td>15.79</td>\n",
              "      <td>45.71</td>\n",
              "      <td>10.61</td>\n",
              "      <td>40.66</td>\n",
              "      <td>16.70</td>\n",
              "      <td>15.18</td>\n",
              "      <td>11.98</td>\n",
              "      <td>-203.70</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>19.13</td>\n",
              "      <td>17.02</td>\n",
              "      <td>-8.50</td>\n",
              "      <td>-13.87</td>\n",
              "      <td>-29.10</td>\n",
              "      <td>-34.29</td>\n",
              "      <td>-24.68</td>\n",
              "      <td>...</td>\n",
              "      <td>-36.75</td>\n",
              "      <td>-15.49</td>\n",
              "      <td>-13.24</td>\n",
              "      <td>20.46</td>\n",
              "      <td>-1.47</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>27.80</td>\n",
              "      <td>-58.20</td>\n",
              "      <td>-58.20</td>\n",
              "      <td>-72.04</td>\n",
              "      <td>-58.01</td>\n",
              "      <td>-30.92</td>\n",
              "      <td>-13.42</td>\n",
              "      <td>-13.98</td>\n",
              "      <td>-5.43</td>\n",
              "      <td>8.71</td>\n",
              "      <td>1.80</td>\n",
              "      <td>36.59</td>\n",
              "      <td>-9.80</td>\n",
              "      <td>-19.53</td>\n",
              "      <td>-19.53</td>\n",
              "      <td>-24.32</td>\n",
              "      <td>-23.88</td>\n",
              "      <td>-33.07</td>\n",
              "      <td>-9.03</td>\n",
              "      <td>3.75</td>\n",
              "      <td>11.61</td>\n",
              "      <td>-12.66</td>\n",
              "      <td>-5.69</td>\n",
              "      <td>12.53</td>\n",
              "      <td>-3.28</td>\n",
              "      <td>-32.21</td>\n",
              "      <td>-32.21</td>\n",
              "      <td>-24.89</td>\n",
              "      <td>-4.86</td>\n",
              "      <td>0.76</td>\n",
              "      <td>-11.70</td>\n",
              "      <td>6.46</td>\n",
              "      <td>16.00</td>\n",
              "      <td>19.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>532.64</td>\n",
              "      <td>535.92</td>\n",
              "      <td>513.73</td>\n",
              "      <td>496.92</td>\n",
              "      <td>456.45</td>\n",
              "      <td>466.00</td>\n",
              "      <td>464.50</td>\n",
              "      <td>486.39</td>\n",
              "      <td>436.56</td>\n",
              "      <td>484.39</td>\n",
              "      <td>469.66</td>\n",
              "      <td>462.30</td>\n",
              "      <td>492.23</td>\n",
              "      <td>441.20</td>\n",
              "      <td>483.17</td>\n",
              "      <td>481.28</td>\n",
              "      <td>535.31</td>\n",
              "      <td>554.34</td>\n",
              "      <td>562.80</td>\n",
              "      <td>540.14</td>\n",
              "      <td>576.34</td>\n",
              "      <td>551.67</td>\n",
              "      <td>556.69</td>\n",
              "      <td>550.86</td>\n",
              "      <td>577.33</td>\n",
              "      <td>562.08</td>\n",
              "      <td>577.97</td>\n",
              "      <td>530.67</td>\n",
              "      <td>553.27</td>\n",
              "      <td>538.33</td>\n",
              "      <td>527.17</td>\n",
              "      <td>532.50</td>\n",
              "      <td>273.66</td>\n",
              "      <td>273.66</td>\n",
              "      <td>292.39</td>\n",
              "      <td>298.44</td>\n",
              "      <td>252.64</td>\n",
              "      <td>233.58</td>\n",
              "      <td>171.41</td>\n",
              "      <td>224.02</td>\n",
              "      <td>...</td>\n",
              "      <td>-51.09</td>\n",
              "      <td>-33.30</td>\n",
              "      <td>-61.53</td>\n",
              "      <td>-89.61</td>\n",
              "      <td>-69.17</td>\n",
              "      <td>-86.47</td>\n",
              "      <td>-140.91</td>\n",
              "      <td>-84.20</td>\n",
              "      <td>-84.20</td>\n",
              "      <td>-89.09</td>\n",
              "      <td>-55.44</td>\n",
              "      <td>-61.05</td>\n",
              "      <td>-29.17</td>\n",
              "      <td>-63.80</td>\n",
              "      <td>-57.61</td>\n",
              "      <td>2.70</td>\n",
              "      <td>-31.25</td>\n",
              "      <td>-47.09</td>\n",
              "      <td>-6.53</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.00</td>\n",
              "      <td>-25.05</td>\n",
              "      <td>-34.98</td>\n",
              "      <td>-32.08</td>\n",
              "      <td>-17.06</td>\n",
              "      <td>-27.77</td>\n",
              "      <td>7.86</td>\n",
              "      <td>-70.77</td>\n",
              "      <td>-64.44</td>\n",
              "      <td>-83.83</td>\n",
              "      <td>-71.69</td>\n",
              "      <td>13.31</td>\n",
              "      <td>13.31</td>\n",
              "      <td>-29.89</td>\n",
              "      <td>-20.88</td>\n",
              "      <td>5.06</td>\n",
              "      <td>-11.80</td>\n",
              "      <td>-28.91</td>\n",
              "      <td>-70.02</td>\n",
              "      <td>-96.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>326.52</td>\n",
              "      <td>347.39</td>\n",
              "      <td>302.35</td>\n",
              "      <td>298.13</td>\n",
              "      <td>317.74</td>\n",
              "      <td>312.70</td>\n",
              "      <td>322.33</td>\n",
              "      <td>311.31</td>\n",
              "      <td>312.42</td>\n",
              "      <td>323.33</td>\n",
              "      <td>311.14</td>\n",
              "      <td>326.19</td>\n",
              "      <td>313.11</td>\n",
              "      <td>313.89</td>\n",
              "      <td>317.96</td>\n",
              "      <td>330.92</td>\n",
              "      <td>341.10</td>\n",
              "      <td>360.58</td>\n",
              "      <td>370.29</td>\n",
              "      <td>369.71</td>\n",
              "      <td>339.00</td>\n",
              "      <td>336.24</td>\n",
              "      <td>319.31</td>\n",
              "      <td>321.56</td>\n",
              "      <td>308.02</td>\n",
              "      <td>296.82</td>\n",
              "      <td>279.34</td>\n",
              "      <td>275.78</td>\n",
              "      <td>289.67</td>\n",
              "      <td>281.33</td>\n",
              "      <td>285.37</td>\n",
              "      <td>281.87</td>\n",
              "      <td>88.75</td>\n",
              "      <td>88.75</td>\n",
              "      <td>67.71</td>\n",
              "      <td>74.46</td>\n",
              "      <td>69.34</td>\n",
              "      <td>76.51</td>\n",
              "      <td>80.26</td>\n",
              "      <td>70.31</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.75</td>\n",
              "      <td>14.29</td>\n",
              "      <td>-14.18</td>\n",
              "      <td>-25.14</td>\n",
              "      <td>-13.43</td>\n",
              "      <td>-14.74</td>\n",
              "      <td>2.24</td>\n",
              "      <td>-31.07</td>\n",
              "      <td>-31.07</td>\n",
              "      <td>-50.27</td>\n",
              "      <td>-39.22</td>\n",
              "      <td>-51.33</td>\n",
              "      <td>-18.53</td>\n",
              "      <td>-1.99</td>\n",
              "      <td>10.43</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>-15.32</td>\n",
              "      <td>-23.38</td>\n",
              "      <td>-27.71</td>\n",
              "      <td>-36.12</td>\n",
              "      <td>-36.12</td>\n",
              "      <td>-15.65</td>\n",
              "      <td>6.63</td>\n",
              "      <td>10.66</td>\n",
              "      <td>-8.57</td>\n",
              "      <td>-8.29</td>\n",
              "      <td>-21.90</td>\n",
              "      <td>-25.80</td>\n",
              "      <td>-29.86</td>\n",
              "      <td>7.42</td>\n",
              "      <td>5.71</td>\n",
              "      <td>-3.73</td>\n",
              "      <td>-3.73</td>\n",
              "      <td>30.05</td>\n",
              "      <td>20.03</td>\n",
              "      <td>-12.67</td>\n",
              "      <td>-8.77</td>\n",
              "      <td>-17.31</td>\n",
              "      <td>-17.35</td>\n",
              "      <td>13.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1107.21</td>\n",
              "      <td>-1112.59</td>\n",
              "      <td>-1118.95</td>\n",
              "      <td>-1095.10</td>\n",
              "      <td>-1057.55</td>\n",
              "      <td>-1034.48</td>\n",
              "      <td>-998.34</td>\n",
              "      <td>-1022.71</td>\n",
              "      <td>-989.57</td>\n",
              "      <td>-970.88</td>\n",
              "      <td>-933.30</td>\n",
              "      <td>-889.49</td>\n",
              "      <td>-888.66</td>\n",
              "      <td>-853.95</td>\n",
              "      <td>-800.91</td>\n",
              "      <td>-754.48</td>\n",
              "      <td>-717.24</td>\n",
              "      <td>-649.34</td>\n",
              "      <td>-605.71</td>\n",
              "      <td>-575.62</td>\n",
              "      <td>-526.37</td>\n",
              "      <td>-490.12</td>\n",
              "      <td>-458.73</td>\n",
              "      <td>-447.76</td>\n",
              "      <td>-419.54</td>\n",
              "      <td>-410.76</td>\n",
              "      <td>-404.10</td>\n",
              "      <td>-425.38</td>\n",
              "      <td>-397.29</td>\n",
              "      <td>-412.73</td>\n",
              "      <td>-446.49</td>\n",
              "      <td>-413.46</td>\n",
              "      <td>-1006.21</td>\n",
              "      <td>-1006.21</td>\n",
              "      <td>-973.29</td>\n",
              "      <td>-986.01</td>\n",
              "      <td>-975.88</td>\n",
              "      <td>-982.20</td>\n",
              "      <td>-953.73</td>\n",
              "      <td>-964.35</td>\n",
              "      <td>...</td>\n",
              "      <td>-694.76</td>\n",
              "      <td>-705.01</td>\n",
              "      <td>-625.24</td>\n",
              "      <td>-604.16</td>\n",
              "      <td>-668.26</td>\n",
              "      <td>-742.18</td>\n",
              "      <td>-820.55</td>\n",
              "      <td>-874.76</td>\n",
              "      <td>-874.76</td>\n",
              "      <td>-853.68</td>\n",
              "      <td>-808.62</td>\n",
              "      <td>-777.88</td>\n",
              "      <td>-712.62</td>\n",
              "      <td>-694.01</td>\n",
              "      <td>-655.74</td>\n",
              "      <td>-599.74</td>\n",
              "      <td>-617.30</td>\n",
              "      <td>-602.98</td>\n",
              "      <td>-539.29</td>\n",
              "      <td>-672.71</td>\n",
              "      <td>-672.71</td>\n",
              "      <td>-594.49</td>\n",
              "      <td>-597.60</td>\n",
              "      <td>-560.77</td>\n",
              "      <td>-501.95</td>\n",
              "      <td>-461.62</td>\n",
              "      <td>-468.59</td>\n",
              "      <td>-513.24</td>\n",
              "      <td>-504.70</td>\n",
              "      <td>-521.95</td>\n",
              "      <td>-594.37</td>\n",
              "      <td>-401.66</td>\n",
              "      <td>-401.66</td>\n",
              "      <td>-357.24</td>\n",
              "      <td>-443.76</td>\n",
              "      <td>-438.54</td>\n",
              "      <td>-399.71</td>\n",
              "      <td>-384.65</td>\n",
              "      <td>-411.79</td>\n",
              "      <td>-510.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5082</th>\n",
              "      <td>-91.91</td>\n",
              "      <td>-92.97</td>\n",
              "      <td>-78.76</td>\n",
              "      <td>-97.33</td>\n",
              "      <td>-68.00</td>\n",
              "      <td>-68.24</td>\n",
              "      <td>-75.48</td>\n",
              "      <td>-49.25</td>\n",
              "      <td>-30.92</td>\n",
              "      <td>-11.88</td>\n",
              "      <td>-4.85</td>\n",
              "      <td>3.88</td>\n",
              "      <td>16.85</td>\n",
              "      <td>26.54</td>\n",
              "      <td>36.70</td>\n",
              "      <td>36.93</td>\n",
              "      <td>38.64</td>\n",
              "      <td>57.02</td>\n",
              "      <td>59.46</td>\n",
              "      <td>78.27</td>\n",
              "      <td>101.61</td>\n",
              "      <td>75.40</td>\n",
              "      <td>115.64</td>\n",
              "      <td>130.04</td>\n",
              "      <td>148.42</td>\n",
              "      <td>190.33</td>\n",
              "      <td>203.23</td>\n",
              "      <td>234.36</td>\n",
              "      <td>272.32</td>\n",
              "      <td>299.24</td>\n",
              "      <td>279.73</td>\n",
              "      <td>344.61</td>\n",
              "      <td>-88.61</td>\n",
              "      <td>-90.03</td>\n",
              "      <td>-68.04</td>\n",
              "      <td>-59.67</td>\n",
              "      <td>-47.47</td>\n",
              "      <td>-33.73</td>\n",
              "      <td>-26.52</td>\n",
              "      <td>-19.49</td>\n",
              "      <td>...</td>\n",
              "      <td>123.45</td>\n",
              "      <td>93.07</td>\n",
              "      <td>80.64</td>\n",
              "      <td>-96.47</td>\n",
              "      <td>-99.12</td>\n",
              "      <td>-79.91</td>\n",
              "      <td>-46.36</td>\n",
              "      <td>-24.50</td>\n",
              "      <td>15.23</td>\n",
              "      <td>37.81</td>\n",
              "      <td>84.92</td>\n",
              "      <td>123.14</td>\n",
              "      <td>147.16</td>\n",
              "      <td>170.86</td>\n",
              "      <td>-95.59</td>\n",
              "      <td>-87.71</td>\n",
              "      <td>-78.36</td>\n",
              "      <td>-51.03</td>\n",
              "      <td>-56.14</td>\n",
              "      <td>-36.15</td>\n",
              "      <td>-26.43</td>\n",
              "      <td>-7.16</td>\n",
              "      <td>-2.19</td>\n",
              "      <td>24.14</td>\n",
              "      <td>41.41</td>\n",
              "      <td>26.69</td>\n",
              "      <td>41.38</td>\n",
              "      <td>61.37</td>\n",
              "      <td>81.24</td>\n",
              "      <td>103.68</td>\n",
              "      <td>139.95</td>\n",
              "      <td>147.26</td>\n",
              "      <td>156.95</td>\n",
              "      <td>155.64</td>\n",
              "      <td>156.36</td>\n",
              "      <td>151.75</td>\n",
              "      <td>-24.45</td>\n",
              "      <td>-17.00</td>\n",
              "      <td>3.23</td>\n",
              "      <td>19.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5083</th>\n",
              "      <td>989.75</td>\n",
              "      <td>891.01</td>\n",
              "      <td>908.53</td>\n",
              "      <td>851.83</td>\n",
              "      <td>755.11</td>\n",
              "      <td>615.78</td>\n",
              "      <td>595.77</td>\n",
              "      <td>458.87</td>\n",
              "      <td>492.84</td>\n",
              "      <td>384.34</td>\n",
              "      <td>288.95</td>\n",
              "      <td>257.42</td>\n",
              "      <td>208.06</td>\n",
              "      <td>224.73</td>\n",
              "      <td>160.31</td>\n",
              "      <td>53.22</td>\n",
              "      <td>61.89</td>\n",
              "      <td>91.62</td>\n",
              "      <td>15.27</td>\n",
              "      <td>-4.70</td>\n",
              "      <td>9.75</td>\n",
              "      <td>37.20</td>\n",
              "      <td>46.91</td>\n",
              "      <td>43.00</td>\n",
              "      <td>55.41</td>\n",
              "      <td>175.08</td>\n",
              "      <td>133.64</td>\n",
              "      <td>218.98</td>\n",
              "      <td>277.05</td>\n",
              "      <td>270.98</td>\n",
              "      <td>112.98</td>\n",
              "      <td>562.45</td>\n",
              "      <td>182.81</td>\n",
              "      <td>166.41</td>\n",
              "      <td>182.28</td>\n",
              "      <td>138.97</td>\n",
              "      <td>196.53</td>\n",
              "      <td>112.61</td>\n",
              "      <td>79.70</td>\n",
              "      <td>45.48</td>\n",
              "      <td>...</td>\n",
              "      <td>-230.39</td>\n",
              "      <td>-225.14</td>\n",
              "      <td>-271.20</td>\n",
              "      <td>116.92</td>\n",
              "      <td>92.22</td>\n",
              "      <td>49.70</td>\n",
              "      <td>53.14</td>\n",
              "      <td>66.41</td>\n",
              "      <td>91.87</td>\n",
              "      <td>29.14</td>\n",
              "      <td>-83.09</td>\n",
              "      <td>-158.39</td>\n",
              "      <td>-278.08</td>\n",
              "      <td>-194.89</td>\n",
              "      <td>13.12</td>\n",
              "      <td>55.98</td>\n",
              "      <td>68.20</td>\n",
              "      <td>69.80</td>\n",
              "      <td>51.73</td>\n",
              "      <td>106.22</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>165.20</td>\n",
              "      <td>83.97</td>\n",
              "      <td>59.61</td>\n",
              "      <td>42.58</td>\n",
              "      <td>86.58</td>\n",
              "      <td>84.11</td>\n",
              "      <td>103.98</td>\n",
              "      <td>88.31</td>\n",
              "      <td>36.64</td>\n",
              "      <td>-26.50</td>\n",
              "      <td>-4.84</td>\n",
              "      <td>-76.30</td>\n",
              "      <td>-37.84</td>\n",
              "      <td>-153.83</td>\n",
              "      <td>-136.16</td>\n",
              "      <td>38.03</td>\n",
              "      <td>100.28</td>\n",
              "      <td>-45.64</td>\n",
              "      <td>35.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5084</th>\n",
              "      <td>273.39</td>\n",
              "      <td>278.00</td>\n",
              "      <td>261.73</td>\n",
              "      <td>236.99</td>\n",
              "      <td>280.73</td>\n",
              "      <td>264.90</td>\n",
              "      <td>252.92</td>\n",
              "      <td>254.88</td>\n",
              "      <td>237.60</td>\n",
              "      <td>238.51</td>\n",
              "      <td>225.68</td>\n",
              "      <td>199.75</td>\n",
              "      <td>177.53</td>\n",
              "      <td>211.27</td>\n",
              "      <td>190.35</td>\n",
              "      <td>226.61</td>\n",
              "      <td>204.55</td>\n",
              "      <td>222.45</td>\n",
              "      <td>204.51</td>\n",
              "      <td>196.45</td>\n",
              "      <td>130.41</td>\n",
              "      <td>155.12</td>\n",
              "      <td>108.21</td>\n",
              "      <td>92.93</td>\n",
              "      <td>99.46</td>\n",
              "      <td>76.12</td>\n",
              "      <td>73.34</td>\n",
              "      <td>29.25</td>\n",
              "      <td>10.76</td>\n",
              "      <td>22.68</td>\n",
              "      <td>46.29</td>\n",
              "      <td>-7.08</td>\n",
              "      <td>158.47</td>\n",
              "      <td>176.38</td>\n",
              "      <td>164.44</td>\n",
              "      <td>124.96</td>\n",
              "      <td>114.69</td>\n",
              "      <td>95.18</td>\n",
              "      <td>100.21</td>\n",
              "      <td>84.05</td>\n",
              "      <td>...</td>\n",
              "      <td>49.68</td>\n",
              "      <td>-52.30</td>\n",
              "      <td>-33.87</td>\n",
              "      <td>-14.22</td>\n",
              "      <td>-51.89</td>\n",
              "      <td>2.48</td>\n",
              "      <td>19.21</td>\n",
              "      <td>38.83</td>\n",
              "      <td>53.35</td>\n",
              "      <td>76.60</td>\n",
              "      <td>7.28</td>\n",
              "      <td>-54.26</td>\n",
              "      <td>-60.81</td>\n",
              "      <td>-14.06</td>\n",
              "      <td>16.64</td>\n",
              "      <td>29.17</td>\n",
              "      <td>35.81</td>\n",
              "      <td>28.45</td>\n",
              "      <td>48.44</td>\n",
              "      <td>47.64</td>\n",
              "      <td>37.64</td>\n",
              "      <td>77.50</td>\n",
              "      <td>61.58</td>\n",
              "      <td>18.71</td>\n",
              "      <td>22.32</td>\n",
              "      <td>60.58</td>\n",
              "      <td>25.00</td>\n",
              "      <td>7.96</td>\n",
              "      <td>-33.64</td>\n",
              "      <td>-23.42</td>\n",
              "      <td>-26.82</td>\n",
              "      <td>-53.89</td>\n",
              "      <td>-48.71</td>\n",
              "      <td>30.99</td>\n",
              "      <td>15.96</td>\n",
              "      <td>-3.47</td>\n",
              "      <td>65.73</td>\n",
              "      <td>88.42</td>\n",
              "      <td>79.07</td>\n",
              "      <td>79.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5085</th>\n",
              "      <td>3.82</td>\n",
              "      <td>2.09</td>\n",
              "      <td>-3.29</td>\n",
              "      <td>-2.88</td>\n",
              "      <td>1.66</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>3.85</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>3.28</td>\n",
              "      <td>6.29</td>\n",
              "      <td>-4.33</td>\n",
              "      <td>5.12</td>\n",
              "      <td>-2.24</td>\n",
              "      <td>-3.27</td>\n",
              "      <td>-7.51</td>\n",
              "      <td>-4.22</td>\n",
              "      <td>-0.82</td>\n",
              "      <td>-1.34</td>\n",
              "      <td>-6.76</td>\n",
              "      <td>-9.87</td>\n",
              "      <td>-2.18</td>\n",
              "      <td>6.43</td>\n",
              "      <td>-6.42</td>\n",
              "      <td>-6.75</td>\n",
              "      <td>-3.84</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-5.66</td>\n",
              "      <td>-4.30</td>\n",
              "      <td>-7.31</td>\n",
              "      <td>-5.81</td>\n",
              "      <td>-11.12</td>\n",
              "      <td>-4.53</td>\n",
              "      <td>4.29</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>3.72</td>\n",
              "      <td>-4.25</td>\n",
              "      <td>3.12</td>\n",
              "      <td>8.85</td>\n",
              "      <td>-2.78</td>\n",
              "      <td>4.61</td>\n",
              "      <td>...</td>\n",
              "      <td>2.25</td>\n",
              "      <td>7.69</td>\n",
              "      <td>2.57</td>\n",
              "      <td>-7.28</td>\n",
              "      <td>-6.67</td>\n",
              "      <td>-8.64</td>\n",
              "      <td>-4.62</td>\n",
              "      <td>-2.87</td>\n",
              "      <td>-1.23</td>\n",
              "      <td>-3.89</td>\n",
              "      <td>-5.00</td>\n",
              "      <td>-1.68</td>\n",
              "      <td>-7.25</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-5.86</td>\n",
              "      <td>-7.83</td>\n",
              "      <td>-9.63</td>\n",
              "      <td>-12.70</td>\n",
              "      <td>-0.65</td>\n",
              "      <td>-8.66</td>\n",
              "      <td>-2.84</td>\n",
              "      <td>-8.58</td>\n",
              "      <td>-3.63</td>\n",
              "      <td>-7.44</td>\n",
              "      <td>-4.98</td>\n",
              "      <td>-3.60</td>\n",
              "      <td>-12.21</td>\n",
              "      <td>-6.65</td>\n",
              "      <td>-5.05</td>\n",
              "      <td>10.86</td>\n",
              "      <td>-3.23</td>\n",
              "      <td>-5.10</td>\n",
              "      <td>-4.61</td>\n",
              "      <td>-9.82</td>\n",
              "      <td>-1.50</td>\n",
              "      <td>-4.65</td>\n",
              "      <td>-14.55</td>\n",
              "      <td>-6.41</td>\n",
              "      <td>-2.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5086</th>\n",
              "      <td>323.28</td>\n",
              "      <td>306.36</td>\n",
              "      <td>293.16</td>\n",
              "      <td>287.67</td>\n",
              "      <td>249.89</td>\n",
              "      <td>218.30</td>\n",
              "      <td>188.86</td>\n",
              "      <td>178.93</td>\n",
              "      <td>118.93</td>\n",
              "      <td>130.68</td>\n",
              "      <td>104.50</td>\n",
              "      <td>63.03</td>\n",
              "      <td>72.07</td>\n",
              "      <td>198.89</td>\n",
              "      <td>570.46</td>\n",
              "      <td>208.08</td>\n",
              "      <td>26.42</td>\n",
              "      <td>44.18</td>\n",
              "      <td>39.85</td>\n",
              "      <td>71.55</td>\n",
              "      <td>81.54</td>\n",
              "      <td>48.87</td>\n",
              "      <td>61.10</td>\n",
              "      <td>49.82</td>\n",
              "      <td>38.50</td>\n",
              "      <td>28.64</td>\n",
              "      <td>20.10</td>\n",
              "      <td>15.07</td>\n",
              "      <td>33.55</td>\n",
              "      <td>36.00</td>\n",
              "      <td>-29.34</td>\n",
              "      <td>-47.82</td>\n",
              "      <td>186.07</td>\n",
              "      <td>112.91</td>\n",
              "      <td>98.15</td>\n",
              "      <td>79.33</td>\n",
              "      <td>55.77</td>\n",
              "      <td>25.82</td>\n",
              "      <td>10.99</td>\n",
              "      <td>-1.19</td>\n",
              "      <td>...</td>\n",
              "      <td>-32.79</td>\n",
              "      <td>-17.46</td>\n",
              "      <td>-4.60</td>\n",
              "      <td>168.11</td>\n",
              "      <td>22.56</td>\n",
              "      <td>-34.79</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-5.64</td>\n",
              "      <td>-15.34</td>\n",
              "      <td>27.73</td>\n",
              "      <td>31.34</td>\n",
              "      <td>15.93</td>\n",
              "      <td>1.88</td>\n",
              "      <td>-5.05</td>\n",
              "      <td>7.50</td>\n",
              "      <td>27.73</td>\n",
              "      <td>-22.82</td>\n",
              "      <td>-40.24</td>\n",
              "      <td>-26.11</td>\n",
              "      <td>-39.12</td>\n",
              "      <td>-26.63</td>\n",
              "      <td>31.11</td>\n",
              "      <td>24.86</td>\n",
              "      <td>42.61</td>\n",
              "      <td>30.88</td>\n",
              "      <td>17.34</td>\n",
              "      <td>-9.08</td>\n",
              "      <td>23.18</td>\n",
              "      <td>22.94</td>\n",
              "      <td>13.89</td>\n",
              "      <td>71.19</td>\n",
              "      <td>0.97</td>\n",
              "      <td>55.20</td>\n",
              "      <td>-1.63</td>\n",
              "      <td>-5.50</td>\n",
              "      <td>-25.33</td>\n",
              "      <td>-41.31</td>\n",
              "      <td>-16.72</td>\n",
              "      <td>-14.09</td>\n",
              "      <td>27.82</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5087 rows × 3197 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       FLUX.1   FLUX.2   FLUX.3  ...  FLUX.3195  FLUX.3196  FLUX.3197\n",
              "0       93.85    83.81    20.10  ...      61.42       5.08     -39.54\n",
              "1      -38.88   -33.83   -58.54  ...       6.46      16.00      19.93\n",
              "2      532.64   535.92   513.73  ...     -28.91     -70.02     -96.67\n",
              "3      326.52   347.39   302.35  ...     -17.31     -17.35      13.98\n",
              "4    -1107.21 -1112.59 -1118.95  ...    -384.65    -411.79    -510.54\n",
              "...       ...      ...      ...  ...        ...        ...        ...\n",
              "5082   -91.91   -92.97   -78.76  ...     -17.00       3.23      19.28\n",
              "5083   989.75   891.01   908.53  ...     100.28     -45.64      35.58\n",
              "5084   273.39   278.00   261.73  ...      88.42      79.07      79.43\n",
              "5085     3.82     2.09    -3.29  ...     -14.55      -6.41      -2.55\n",
              "5086   323.28   306.36   293.16  ...     -16.72     -14.09      27.82\n",
              "\n",
              "[5087 rows x 3197 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYlFRpMUoX0o"
      },
      "source": [
        "Now, let's get only the target variables from the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow3bOVajkEos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b675418-2a0c-443b-f46f-6de925c2ef41"
      },
      "source": [
        "# Student Action: Using the 'iloc[]' function, retrieve only the first column, i.e., the 'LABEL' column from the training dataset.\n",
        "y_train = exo_train_df.iloc[:,0]\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       2\n",
              "1       2\n",
              "2       2\n",
              "3       2\n",
              "4       2\n",
              "       ..\n",
              "5082    1\n",
              "5083    1\n",
              "5084    1\n",
              "5085    1\n",
              "5086    1\n",
              "Name: LABEL, Length: 5087, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4c2YLzWdtiC"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSKFSFb5gZge"
      },
      "source": [
        "#### Activity 4: Fitting The Model\n",
        "\n",
        "Now that we have separated the feature and target variables for deploying the `RandomForestClassifier` model, let's train the model with the feature variables using the `fit()` function. The steps to be followed are described below.\n",
        "\n",
        "1. First, call the `RandomForestClassifier` module with inputs as `n_jobs=-1` and `n_estimators=50`. Store the function in a variable with the name `rf_clf`.\n",
        "\n",
        "  For the time being, ignore the reason behind providing the `n_jobs=-1` parameter as an input.\n",
        "\n",
        "  ```\n",
        "  rf_clf = RandomForestClassifier(n_jobs=-1, n_estimators=50)\n",
        "  ```\n",
        "\n",
        "  The `n_estimators` parameter defines the number of decision trees in a Random Forest. Therefore, `n_estimators=50` means that the forest contains `50` decision trees. If `n_estimators` parameter is not defined by a user, then by default, the forest contains `100` decision trees.\n",
        "\n",
        "2. Call the `fit()` function with `x_train` and `y_train` as inputs.\n",
        "\n",
        "  ```\n",
        "  rf_clf.fit(x_train, y_train)\n",
        "  ```\n",
        "3. Call the `score()` function with `x_train` and `y_train` as inputs to check the accuracy score of the model. This step is actually not required. If you wish, you can skip this step.\n",
        "  \n",
        "  ```\n",
        "  rf_clf.score(x_train, y_train)\n",
        "  ```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAU1jEBVkHG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c861d031-3975-4706-83ee-e4e51041b872"
      },
      "source": [
        "# Teacher Action: Train the 'RandomForestClassifier' model using the 'fit()' function.\n",
        "\n",
        "# 1. First, call the 'RandomForestClassifier' module with inputs as 'n_jobs = - 1' & 'n_estimators=50'. Store it in a variable with the name 'rf_clf'.\n",
        "# For the time being, ignore the reason behind providing the 'n_jobs=-1' parameter as an input.\n",
        "rf_clf=RandomForestClassifier(n_jobs=-1,n_estimators=50)\n",
        "# 2. Call the 'fit()' function with 'x_train' and 'y_train' as inputs.\n",
        "rf_clf.fit(x_train,y_train)\n",
        "# 3. Call the 'score()' function with 'x_train' and 'y_train' as inputs to check the accuracy score of the model.\n",
        "rf_clf.score(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKq3HlbxhU0k"
      },
      "source": [
        "As you can see, we have deployed the `RandomForestClassifier` model with an accuracy of 100% (the number `1.0` signifies 100% accuracy).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV57P4UFh1rt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIi2Gikph5HQ"
      },
      "source": [
        "#### Activity 5: Target & Feature Variables From Test Dataset^^\n",
        "\n",
        "Now we need to make predictions on the test dataset. So, we just need to extract feature variables from the test dataset using the `iloc[]` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN1nsa2qpr80"
      },
      "source": [
        "# Student Action: Using the 'iloc[]' function, extract the feature variables from the test dataset.\n",
        "x_test=exo_test_df.iloc[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsZe8fyeiXBG"
      },
      "source": [
        "Let's also extract the target variable from the test dataset so that we can compare the actual target values with the predicted values later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVMq86Y5p5ol"
      },
      "source": [
        "# Student Action: Using the 'iloc[]' function, extract the target variable from the test dataset.\n",
        "y_test=exo_test_df.iloc[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExuN-AU6nd5p",
        "outputId": "6fc98e13-8798-47be-8d76-587190a5d1d4"
      },
      "source": [
        "exo_test_df[\"LABEL\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    565\n",
              "2      5\n",
              "Name: LABEL, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f3OVTo4ioQk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz8BPprpipOq"
      },
      "source": [
        "#### Activity 6: The `predict()` Function^^^\n",
        "\n",
        "Now, let's make predictions on the test dataset by calling the `predict()` function with the features variables of the test dataset as an input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF_lb5Fcp8zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c77757d3-f3e9-4777-b31c-d5483c6fd90f"
      },
      "source": [
        "# Student Action: Make predictions on the test dataset by using the 'predict()' function.\n",
        "y_predict=(rf_clf.predict(x_test))\n",
        "y_predict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pKzHPiEjCSI"
      },
      "source": [
        "The predict function returns a NumPy array of the predicted values. You can verify it using the `type()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOz8o4fJp-_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23a6be4-ebbd-4539-c0a2-159bced0b326"
      },
      "source": [
        "# Student Action: Using the 'type()' function, verify that the predicted values are obtained in the form of a NumPy array.\n",
        "type(y_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhdBmNx8jWQv"
      },
      "source": [
        "The actual target values are stored in a Pandas series. So, for the sake of consistency, let's convert the NumPy array of the predicted values into a Pandas series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF3skQa0qBeO"
      },
      "source": [
        "# Student Action: Convert the NumPy array of predicted values into a Pandas series.\n",
        "y_predict=pd.Series(y_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQwrexkrjrdE"
      },
      "source": [
        "Now, let's count the number of stars classified as `1` and `2`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk7UnroAqTUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb2257b-32e9-47e6-edc6-ea8b974f2f08"
      },
      "source": [
        "# Student Action: Using the 'value_counts()' function, count the number of times 1 and 2 occur in the predicted values.\n",
        "y_predict\n",
        "y_predict.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    570\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfKiAcaMj5xF"
      },
      "source": [
        "As you can see, we did not get the expected results. The model should have classified all the stars having a planet as `2`. Ideally, the Random Forest Classifier model should have classified `565` values as `1` and the remaining `5` values as `2`.\n",
        "\n",
        "In this case, even though the accuracy of a prediction model is high but according to the problem statement, it is not giving the desired result. Hence, **accuracy alone is not the metric to test the efficacy of a prediction model.**\n",
        "\n",
        "In the next class, we will try to investigate why Random Forest Classifier failed to classify even a single star as `2`. Based on the investigation, we will try to improve the model and then deploy it again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3WclLnZkFfz"
      },
      "source": [
        "---"
      ]
    }
  ]
}